{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAD geocoding\n",
    "\n",
    "Here we geocode GtR organisations at the LAD level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(a_list):\n",
    "    return([x for el in a_list for x in el])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For geocoding into lads\n",
    "import geopandas as gp\n",
    "\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lad shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_shape = gp.read_file(\n",
    "    '../data/external/Local_Authority_Districts_December_2017_Full_Clipped_Boundaries_in_Great_Britain.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_shape.to_crs(epsg=4326,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scottish_lads = {'Aberdeen City',\n",
    " 'Aberdeenshire',\n",
    " 'Angus',\n",
    " 'Argyll and Bute',\n",
    " 'Clackmannanshire',\n",
    " 'Dumfries and Galloway',\n",
    " 'Dundee City',\n",
    " 'East Ayrshire',\n",
    " 'East Dunbartonshire',\n",
    " 'East Lothian',\n",
    " 'East Renfrewshire',\n",
    " 'Edinburgh, City of',\n",
    " 'Eilean Siar',\n",
    " 'Falkirk',\n",
    " 'Fife',\n",
    " 'Glasgow City',\n",
    " 'Highland',\n",
    " 'Inverclyde',\n",
    " 'Midlothian',\n",
    " 'Moray',\n",
    " 'North Ayrshire',\n",
    " 'North Lanarkshire',\n",
    " 'Orkney Islands',\n",
    " 'Perth and Kinross',\n",
    " 'Renfrewshire',\n",
    " 'Scottish Borders',\n",
    " 'Shetland Islands',\n",
    " 'South Ayrshire',\n",
    " 'South Lanarkshire',\n",
    " 'Stirling',\n",
    " 'West Dunbartonshire',\n",
    " 'West Lothian'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_lads = {'E07000146': 'King`s Lynn and West Norfolk',\n",
    " 'E07000112': 'Shepway',\n",
    " 'W06000001': 'Anglesey',\n",
    " 'W06000014': 'The Vale of Glamorgan',\n",
    " 'W06000016': 'Rhondda, Cynon, Taff',\n",
    " 'S12000036': 'Edinburgh, City of',\n",
    " 'S12000013': 'Eilean Siar',\n",
    " '95AA': 'Antrim',\n",
    " '95BB': 'Ards',\n",
    " '95CC': 'Armagh',\n",
    " '95DD': 'Ballymena',\n",
    " '95EE': 'Ballymoney',\n",
    " '95FF': 'Banbridge',\n",
    " '95GG': 'Belfast',\n",
    " '95HH': 'Carrickfergus',\n",
    " '95II': 'Castlereagh',\n",
    " '95JJ': 'Coleraine',\n",
    " '95KK': 'Cookstown',\n",
    " '95LL': 'Craigavon',\n",
    " '95MM': 'Derry',\n",
    " '95NN': 'Down',\n",
    " '95OO': 'Dungannon',\n",
    " '95PP': 'Fermanagh',\n",
    " '95QQ': 'Larne',\n",
    " '95RR': 'Limavady',\n",
    " '95SS': 'Lisburn',\n",
    " '95TT': 'Magherafelt',\n",
    " '95UU': 'Moyle',\n",
    " '95VV': 'Newry and Mourne',\n",
    " '95WW': 'Newtownabbey',\n",
    " '95XX': 'North Down',\n",
    " '95YY': 'Omagh',\n",
    " '95ZZ': 'Strabane'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_shape['lad_name'] = [rename_lads[x] if x in rename_lads.keys() else name for x,name in\n",
    "                        zip(lad_shape['lad17cd'],lad_shape['lad17nm'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load files and spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_dir = '../data/raw/gtr/2019-05-02/'\n",
    "\n",
    "orgs, orgs_locs = [pd.read_csv(gtr_dir+name) for name in ['/gtr_organisations.csv','/gtr_organisations_locations.csv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs_locs['coordinates'] = orgs_locs[['longitude','latitude']].apply(Point,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_locs = gp.GeoDataFrame(orgs_locs,geometry='coordinates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial join (point in polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_gtr = gp.sjoin(org_locs,lad_shape,op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad_gtr.lad_name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lad_gtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(org_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_ids = set(lad_gtr['id'])\n",
    "\n",
    "orgs_locs.loc[[x not in matched_ids for x in org_locs['id']]]['country_name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the unmatched orgs have missing geographical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an org id - lad lookup\n",
    "org_lad_lookup = {x['id']:[x['lad17cd'],x['lad_name']] for n,x in lad_gtr.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dfs for matching\n",
    "\n",
    "I want a df where every row is a project. The columns represent:\n",
    "\n",
    "* The LAD of the lead organisation\n",
    "* The LADs of the participant organisations\n",
    "* Flags for whether the lead and participating organisations are Scottish or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = pd.read_csv('../data/raw/gtr/2019-06-13/gtr_link_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_link = link.loc[['_ORG' in x for x in link['rel']]].reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_link.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_link_grouped = org_link.groupby(['project_id','rel'])['id'].apply(lambda x: list(set(x))).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_link_grouped_wide = pd.pivot_table(org_link_grouped,index='project_id',columns='rel',values='id',aggfunc=lambda x: list(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the lookup - we need some nested loops to deal with missing values and missing orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lad_allocator(var_name,df):\n",
    "    '''\n",
    "    Looks up the lad code and name of organisations participating in a project\n",
    "    '''\n",
    "    \n",
    "    df[f'{var_name.lower()}_lad_code'],df[f'{var_name.lower()}_lad_name'] = [\n",
    "    [[] if type(x)==float else [org_lad_lookup[el][n] for el in x if el in org_lad_lookup.keys()] for x in df[f'{var_name}_ORG']] for\n",
    "    n in [0,1]]\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these returns a geolabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_geo = lad_allocator('LEAD',org_link_grouped_wide)\n",
    "org_geo = lad_allocator('PARTICIPANT',org_link_grouped_wide)\n",
    "org_geo = lad_allocator('PP',org_link_grouped_wide)\n",
    "org_geo = lad_allocator('COLLAB',org_link_grouped_wide)\n",
    "org_geo = lad_allocator('FELLOW',org_link_grouped_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group all the organisation geo data, and all the involved (all except the lead) in two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_geo['all_lad_code'],org_geo['all_lad_name'] = [[flatten_list([row[name+f'_lad_{var}'] for name in ['lead','participant','pp','collab','fellow']]) for\n",
    "                                                             n, row in org_geo.iterrows()] for var in ['code','name']]\n",
    "\n",
    "\n",
    "org_geo['involved_lad_code'],org_geo['involved_lad_name'] = [[flatten_list([row[name+f'_lad_{var}'] for name in ['participant','pp','collab','fellow']]) for\n",
    "                                                             n, row in org_geo.iterrows()] for var in ['code','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_geo.to_csv(f'../data/temp_scotland/{today_str}_gtr_org_lad_labelled.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with the combined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/14_6_2019_combined_gtr_projects.csv',compression='zip')\n",
    "df = df[[x for x in df.columns if 'Unnamed' not in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_geo = pd.merge(df,org_geo,left_on='project_id',right_on='project_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)-len(df_w_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_ids = set(df_w_geo.project_id)\n",
    "\n",
    "unmatched = df.loc[[x not in matched_ids for x in df['project_id']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_ids = set(unmatched['project_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link.loc[[x in unmatched_ids for x in link['project_id']]]['rel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No organisation data for the unmatched ones! \n",
    "\n",
    "**Todo** check with Joel and Russ about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_w_geo_w_lead = df_w_geo.dropna(axis=0,subset=['lead_lad_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_geo['lead_scot'],df_w_geo['inv_scot'] = [[any(el in scottish_lads for el in x) for x in df_w_geo[var]] for var in ['lead_lad_name','involved_lad_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_geo['inv_scot_n'] = [np.sum([el in scottish_lads for el in x]) for x in df_w_geo['all_lad_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_geo.to_csv(f'../data/temp_scotland/{today_str}_gtr_projects_geo_labelled.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(flatten_list(df_w_geo['lead_lad_name'])).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation to project lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Org focused has two columns, one with lists of projects an organisation has participated in and another with the list of roles \n",
    "#org_focused = pd.concat([org_link.groupby('id')[var].apply(lambda x: list(x)) for var in ['project_id','rel']],axis=1)\n",
    "\n",
    "\n",
    "org_focused = org_link.set_index('id').iloc[:,2:] #The positional indexing is to remove some unnecessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Org name lookup\n",
    "org_name_lookup,org_lad_lookup = [df.set_index('id').to_dict(orient='index') for df in [orgs,lad_gtr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label the org_focused dataframe with names and places\n",
    "\n",
    "org_focused['name'],org_focused['lad'] = [[df[org_id][var] if org_id in df.keys() else np.nan for org_id in org_focused.index] for df,var in zip(\n",
    "    [org_name_lookup,org_lad_lookup],['name','lad_name'])]\n",
    "\n",
    "org_focused.reset_index(drop=False,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the enriched project dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_meta = pd.read_csv('../data/temp_scotland/21_5_2019_gtr_projects_geo_labelled.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_proj = pd.merge(org_focused,proj_meta,left_on='project_id',right_on='project_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to parse the lists in the data\n",
    "\n",
    "list_var = [x for x in org_proj.columns if '_lad_' in x]\n",
    "\n",
    "#If the column is in the list above, then parse it\n",
    "for c in org_proj.columns:\n",
    "    \n",
    "    if c in list_var:\n",
    "        org_proj[c] = [literal_eval(x) for x in org_proj[c]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_proj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a couple of variables that will help with the analysis later\n",
    "\n",
    "#This is capturing if an organisation is in a local collaboration\n",
    "\n",
    "org_proj['local_collab'] = [x['all_lad_name'].count(x['lad'])>1 if pd.isnull(x['lad'])==False else np.nan for pid,x in org_proj.iterrows()]\n",
    "\n",
    "#It will easy to turn this into a measure of Scottish local collaborations (they are local collaborations for organisations in Scotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And we create another about Scottish collaborations\n",
    "org_proj['scot_collab'] = [(x['lad'] in scottish_lads) & (len(scottish_lads & set(x['all_lad_name']))>1) for pid, x in org_proj.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to tidy up this df\n",
    "\n",
    "What variables do we want to create?\n",
    "\n",
    "* Total number of projects\n",
    "* Total number of projects led\n",
    "* Total level of funding\n",
    "* Total level of funding in projects led\n",
    "* Discipline distribution (projects led)\n",
    "* Funder distribution\n",
    "* Output distribution (projects involving)\n",
    "* Local collaborations\n",
    "* Scottish local collaborations\n",
    "* Scottish local collaborations\n",
    "* Top Scottish collaborator (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_org_stats(df):\n",
    "    '''\n",
    "    Calculates key statistics for organisations in the GTR including:\n",
    "    \n",
    "        Total number of projects\n",
    "        Total number of projects led\n",
    "        Total level of funding\n",
    "        Total level of funding in projects led\n",
    "        Discipline distribution\n",
    "        Funder distribution\n",
    "        Output distribution (projects involving organisation)\n",
    "        How many collaborations locally\n",
    "        Scottish local collaborations\n",
    "        Scottish local collaborations\n",
    "        Top Scottish collaborator (?)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Storage for results we will concatenate at the end\n",
    "    grouped_results = []\n",
    "    \n",
    "\n",
    "    #Created a grouped df\n",
    "    df_by_org = df.groupby('id')\n",
    "    \n",
    "    \n",
    "    #Get the list of projects and collaborations\n",
    "    proj_rel_lists = pd.concat([df_by_org[var].apply(lambda x: list(x)) for var in ['project_id','rel']],axis=1)\n",
    "    \n",
    "    #Number of projects\n",
    "    proj_rel_lists['project_n'] = [len(x) for x in proj_rel_lists['project_id']]\n",
    "\n",
    "    #Number of led projects\n",
    "    proj_rel_lists['lead_project_n'] = [np.sum([x=='LEAD_ORG' for x in statuses]) for statuses in proj_rel_lists['rel']]\n",
    "    \n",
    "    #Append to the store\n",
    "    grouped_results.append(proj_rel_lists)\n",
    "    \n",
    "    #Amount of funding\n",
    "    funding_total = df_by_org['amount'].sum()\n",
    "    \n",
    "    #Amount of funding in led projects\n",
    "    #We subset the org links to only focus on funded projects\n",
    "    funding_led = df.loc[df['rel']=='LEAD_ORG'].groupby('id')['amount'].sum()\n",
    "    \n",
    "    #All funding\n",
    "    all_funding = pd.concat([funding_total,funding_led],axis=1)\n",
    "    all_funding.columns = ['all_funding','led_funding']\n",
    "    \n",
    "    \n",
    "    grouped_results.append(all_funding)\n",
    "    \n",
    "    #Various distributions of categorical variables\n",
    "    disc_mix,fund_mix,grant_mix = [df_by_org[var].value_counts().rename(columns={var:'n'} #This is to avoid the conflict when resetting the index\n",
    "                                                          ).reset_index(drop=False).pivot(\n",
    "        index='id',columns=var,values=0).fillna(0) for var in ['disc_top','funder','grant_category']]\n",
    "    \n",
    "    #Clean column names for grant types and funders (this could be a list comprehension)\n",
    "    grant_mix.columns = ['grantcat_'+re.sub(' ','_',x.lower()) for x in grant_mix.columns]\n",
    "    fund_mix.columns = ['funder_'+re.sub(' ','_',x.lower()) for x in fund_mix.columns]\n",
    "    \n",
    "    \n",
    "    grouped_results.append(pd.concat([disc_mix,fund_mix,grant_mix],axis=1))\n",
    "    \n",
    "    #Outputs\n",
    "    #Get the variables\n",
    "    output_vars = [x for x in df.columns if 'out_' in x]\n",
    "    \n",
    "    #Calculate sum  of outputs over all papers\n",
    "    output_mix = df_by_org[output_vars].sum()\n",
    "    \n",
    "    grouped_results.append(output_mix)\n",
    "    \n",
    "    #Local collaborators:\n",
    "    #Create a local analysis df\n",
    "    collabs = pd.concat([df_by_org[var].sum() for var in ['local_collab','scot_collab']],axis=1)\n",
    "    \n",
    "    #Cast as int\n",
    "    collabs['local_collab'],collabs['scot_collab']= [collabs[v].astype(int) for v in ['local_collab','scot_collab']]\n",
    "    \n",
    "    #print(collabs['local_collab'].head())\n",
    "    \n",
    "    \n",
    "    grouped_results.append(collabs)\n",
    "    \n",
    "    #return(grouped_results)\n",
    "    \n",
    "    return(pd.concat(grouped_results,axis=1))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_df = calculate_org_stats(org_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now we need to add names and LADs\n",
    "\n",
    "org_df['name'],org_df['lad'] = [[df[org_id][var] if org_id in df.keys() else np.nan for org_id in org_df.index] for df,var in zip(\n",
    "    [org_name_lookup,org_lad_lookup],['name','lad_name'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_df.to_csv(f'../data/processed/{today_str}_organisation_activities.csv',compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
